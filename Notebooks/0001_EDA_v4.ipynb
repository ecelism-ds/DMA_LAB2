{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trabajo Final - Laboratorio II**\n",
    "\n",
    "*Integrantes:* \n",
    "* Celis Mendoza, Elemir\n",
    "* Dellatore, Andrés\n",
    "* Forconi, Gerónimo \n",
    "* Lignini, Maira\n",
    "* Palomeque, Claudia\n",
    "* Postiglione, Sebastián"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Objetivo\n",
    "\n",
    "Se busca predecir la velocidad a la que se adopta una mascota.\n",
    "En este caso, la velocidad de adopción se determina por la rapidez con la que todas las mascotas del grupo son adoptadas.\n",
    "\n",
    "Los datos que se disponen incluyen información de texto, tabulares y datos de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Información disponible\n",
    "\n",
    "## Variables dataset inicial\n",
    "\n",
    "* PetID - Identificador único en forma de hash del perfil de la mascota\n",
    "* Tipo - Tipo de animal (1 = Perro, 2 = Gato)\n",
    "* Nombre - Nombre de la mascota (Vacío si no tiene nombre)\n",
    "* Edad - Edad de la mascota cuando se registró, en meses\n",
    "* Raza1 - Raza principal de la mascota \n",
    "* Raza2 - Raza secundaria de la mascota, si es de raza mixta \n",
    "* Género - Género de la mascota (1 = Macho, 2 = Hembra, 3 = Mixto, si el perfil representa a un grupo de mascotas)\n",
    "* Color1 - Color 1 de la mascota \n",
    "* Color2 - Color 2 de la mascota \n",
    "* Color3 - Color 3 de la mascota \n",
    "* TamañoMaduro - Tamaño en la madurez (1 = Pequeño, 2 = Mediano, 3 = Grande, 4 = Extra Grande, 0 = No Especificado)\n",
    "* LongitudPelaje - Longitud del pelaje (1 = Corto, 2 = Mediano, 3 = Largo, 0 = No Especificado)\n",
    "* Vacunado - Si la mascota ha sido vacunada (1 = Sí, 2 = No, 3 = No Estoy Seguro)\n",
    "* Desparasitado - Si la mascota ha sido desparasitada (1 = Sí, 2 = No, 3 = No Estoy Seguro)\n",
    "* Esterilizado - Si la mascota ha sido esterilizada / castrada (1 = Sí, 2 = No, 3 = No Estoy Seguro)\n",
    "* Salud - Condición de salud (1 = Saludable, 2 = Lesión Menor, 3 = Lesión Grave, 0 = No Especificado)\n",
    "* Cantidad - Número de mascotas representadas en el perfil\n",
    "* Tarifa - Tarifa de adopción (0 = Gratis)\n",
    "* Estado - Ubicación en el estado de Malasia \n",
    "* IDRescatador - Identificador único en forma de hash del rescatador\n",
    "* CantidadVideos - Total de videos subidos para esta mascota\n",
    "* CantidadFotos - Total de fotos subidas para esta mascota\n",
    "* Descripción - Descripción escrita del perfil de esta mascota. El idioma principal utilizado es el inglés, con algunas descripciones en malayo o chino.\n",
    "\n",
    "## Variable Target\n",
    "\n",
    "*AdoptionSpeed* - Velocidad de adopción (categorizada).\n",
    "\n",
    "0 - La mascota fue adoptada el mismo día en que fue listada.\n",
    "\n",
    "1 - La mascota fue adoptada entre 1 y 7 días (1ra semana) después de ser listada.\n",
    "\n",
    "2 - La mascota fue adoptada entre 8 y 30 días (1er mes) después de ser listada.\n",
    "\n",
    "3 - La mascota fue adoptada entre 31 y 90 días (2do y 3er mes) después de ser listada.\n",
    "\n",
    "4 - No hubo adopción después de 100 días de ser listada. (En este conjunto de datos, no hay mascotas que hayan esperado entre 90 y 100 días). \n",
    "\n",
    "## Información adicional\n",
    "\n",
    "* Metadatos de las imágenes\n",
    "* Datos de Sentimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1 : EDA \n",
    "\n",
    "Analisis descriptivo utilizando sólo la información disponible en Train (data/train/train.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n",
      "C:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Temp\\ipykernel_18680\\2342400932.py:5: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n"
     ]
    }
   ],
   "source": [
    "# 1. Importo librerias\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import cv2 #Para cargar/mostrar/procesar imagenes\n",
    "import json\n",
    "import glob #Para listar los archivos en una carpeta\n",
    "\n",
    "# Librerias propias (contienen los modelos)\n",
    "import model_metadata\n",
    "import model_sentiment\n",
    "\n",
    "# cargar el resto de las librerias necesarias acá\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código Auxiliar!\n",
    "#Para borrar la cache de las librerias propias\n",
    "#import importlib\n",
    "#importlib.reload(model_sentiment)\n",
    "#importlib.reload(model_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type                     Name  Age  Breed1  Breed2  Gender  Color1  \\\n",
      "PetID                                                                           \n",
      "86e1089a3     2                   Nibble    3     299       0       1       1   \n",
      "6296e909a     2              No Name Yet    1     265       0       1       1   \n",
      "3422e4906     1                   Brisco    1     307       0       1       2   \n",
      "5842f1ff5     1                     Miko    4     307       0       2       1   \n",
      "850a43f90     1                   Hunter    1     307       0       1       1   \n",
      "d24c30b4b     2                      NaN    3     266       0       2       5   \n",
      "1caa6fcdb     2                    BULAT   12     264     264       1       1   \n",
      "97aa9eeac     1  Siu Pak & Her 6 Puppies    0     307       0       2       1   \n",
      "c06d167ca     2                      NaN    2     265       0       2       6   \n",
      "7a0942d61     2                    Kitty   12     265       0       2       1   \n",
      "\n",
      "           Color2  Color3  MaturitySize  ...  Sterilized  Health  Quantity  \\\n",
      "PetID                                    ...                                 \n",
      "86e1089a3       7       0             1  ...           2       1         1   \n",
      "6296e909a       2       0             2  ...           3       1         1   \n",
      "3422e4906       7       0             2  ...           2       1         1   \n",
      "5842f1ff5       2       0             2  ...           2       1         1   \n",
      "850a43f90       0       0             2  ...           2       1         1   \n",
      "d24c30b4b       6       0             2  ...           2       1         1   \n",
      "1caa6fcdb       0       0             2  ...           3       1         1   \n",
      "97aa9eeac       2       7             2  ...           2       1         6   \n",
      "c06d167ca       0       0             2  ...           2       1         1   \n",
      "7a0942d61       7       0             2  ...           3       1         1   \n",
      "\n",
      "           Fee  State                         RescuerID  VideoAmt  \\\n",
      "PetID                                                               \n",
      "86e1089a3  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n",
      "6296e909a    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
      "3422e4906    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
      "5842f1ff5  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n",
      "850a43f90    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n",
      "d24c30b4b    0  41326  22fe332bf9c924d4718005891c63fbed         0   \n",
      "1caa6fcdb  300  41326  1e0b5a458b5b77f5af581d57ebf570b3         0   \n",
      "97aa9eeac    0  41326  1fba5f6e5480946254590d48f9c5198d         0   \n",
      "c06d167ca    0  41326  d8af7afece71334473575c9f70daf00d         0   \n",
      "7a0942d61    0  41326  1f3f36e4b18e94855b3e88af0852fdc4         0   \n",
      "\n",
      "                                                 Description PhotoAmt  \\\n",
      "PetID                                                                   \n",
      "86e1089a3  Nibble is a 3+ month old ball of cuteness. He ...      1.0   \n",
      "6296e909a  I just found it alone yesterday near my apartm...      2.0   \n",
      "3422e4906  Their pregnant mother was dumped by her irresp...      7.0   \n",
      "5842f1ff5  Good guard dog, very alert, active, obedience ...      8.0   \n",
      "850a43f90  This handsome yet cute boy is up for adoption....      3.0   \n",
      "d24c30b4b  This is a stray kitten that came to my house. ...      2.0   \n",
      "1caa6fcdb  anyone within the area of ipoh or taiping who ...      3.0   \n",
      "97aa9eeac  Siu Pak just give birth on 13/6/10 to 6puppies...      9.0   \n",
      "c06d167ca  healthy and active, feisty kitten found in nei...      6.0   \n",
      "7a0942d61  Very manja and gentle stray cat found, we woul...      2.0   \n",
      "\n",
      "           AdoptionSpeed  \n",
      "PetID                     \n",
      "86e1089a3              2  \n",
      "6296e909a              0  \n",
      "3422e4906              3  \n",
      "5842f1ff5              2  \n",
      "850a43f90              2  \n",
      "d24c30b4b              2  \n",
      "1caa6fcdb              1  \n",
      "97aa9eeac              3  \n",
      "c06d167ca              1  \n",
      "7a0942d61              4  \n",
      "\n",
      "[10 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14993 entries, 86e1089a3 to a83d95ead\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Type           14993 non-null  int64  \n",
      " 1   Name           13728 non-null  object \n",
      " 2   Age            14993 non-null  int64  \n",
      " 3   Breed1         14993 non-null  int64  \n",
      " 4   Breed2         14993 non-null  int64  \n",
      " 5   Gender         14993 non-null  int64  \n",
      " 6   Color1         14993 non-null  int64  \n",
      " 7   Color2         14993 non-null  int64  \n",
      " 8   Color3         14993 non-null  int64  \n",
      " 9   MaturitySize   14993 non-null  int64  \n",
      " 10  FurLength      14993 non-null  int64  \n",
      " 11  Vaccinated     14993 non-null  int64  \n",
      " 12  Dewormed       14993 non-null  int64  \n",
      " 13  Sterilized     14993 non-null  int64  \n",
      " 14  Health         14993 non-null  int64  \n",
      " 15  Quantity       14993 non-null  int64  \n",
      " 16  Fee            14993 non-null  int64  \n",
      " 17  State          14993 non-null  int64  \n",
      " 18  RescuerID      14993 non-null  object \n",
      " 19  VideoAmt       14993 non-null  int64  \n",
      " 20  Description    14980 non-null  object \n",
      " 21  PhotoAmt       14993 non-null  float64\n",
      " 22  AdoptionSpeed  14993 non-null  int64  \n",
      "dtypes: float64(1), int64(19), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#2. Lectura Dataset inicial \n",
    "train_data = pd.read_csv('../data/train/train.csv', index_col='PetID') \n",
    "\n",
    "print (train_data.head(10))\n",
    "# Info del dataset\n",
    "\n",
    "train_data.info ()\n",
    "#14.993 registros\n",
    "#23 variables\n",
    "\n",
    "# Se presentan variables como númericas cuando en realidad el número en cuestión es una categoría.\n",
    "# Hay que transformarla \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Transformación de los datos\n",
    "\n",
    "train_data['Type'] = train_data['Type'].astype('category')\n",
    "train_data['Breed1'] = train_data['Breed1'].astype('category')\n",
    "train_data['Breed2'] = train_data['Breed2'].astype('category')\n",
    "train_data['Gender'] = train_data['Gender'].astype('category')\n",
    "train_data['Color1'] = train_data['Color1'].astype('category')\n",
    "train_data['Color2'] = train_data['Color2'].astype('category')\n",
    "train_data['Color3'] = train_data['Color3'].astype('category')\n",
    "train_data['MaturitySize'] = train_data['MaturitySize'].astype('category')\n",
    "train_data['FurLength'] = train_data['FurLength'].astype('category')\n",
    "train_data['Vaccinated'] = train_data['Vaccinated'].astype('category')\n",
    "train_data['Dewormed'] = train_data['Dewormed'].astype('category')\n",
    "train_data['Sterilized'] = train_data['Sterilized'].astype('category')\n",
    "train_data['Health'] = train_data['Health'].astype('category')\n",
    "train_data['State'] = train_data['State'].astype('category')\n",
    "train_data['AdoptionSpeed'] = train_data['AdoptionSpeed'].astype('category')\n",
    "#train_data.info()--> ok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas para variables continuas:\n",
      "                Age      Quantity           Fee      VideoAmt      PhotoAmt\n",
      "count  14993.000000  14993.000000  14993.000000  14993.000000  14993.000000\n",
      "mean      10.452078      1.576069     21.259988      0.056760      3.889215\n",
      "std       18.155790      1.472477     78.414548      0.346185      3.487810\n",
      "min        0.000000      1.000000      0.000000      0.000000      0.000000\n",
      "25%        2.000000      1.000000      0.000000      0.000000      2.000000\n",
      "50%        3.000000      1.000000      0.000000      0.000000      3.000000\n",
      "75%       12.000000      1.000000      0.000000      0.000000      5.000000\n",
      "max      255.000000     20.000000   3000.000000      8.000000     30.000000\n",
      "\n",
      "Frecuencias para Type:\n",
      "Type\n",
      "1    8132\n",
      "2    6861\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Breed1:\n",
      "Breed1\n",
      "307    5927\n",
      "266    3634\n",
      "265    1258\n",
      "299     342\n",
      "264     296\n",
      "       ... \n",
      "99        1\n",
      "93        1\n",
      "85        1\n",
      "81        1\n",
      "192       1\n",
      "Name: count, Length: 176, dtype: int64\n",
      "\n",
      "Frecuencias para Breed2:\n",
      "Breed2\n",
      "0      10762\n",
      "307     1727\n",
      "266      599\n",
      "265      321\n",
      "299      138\n",
      "       ...  \n",
      "146        1\n",
      "130        1\n",
      "122        1\n",
      "239        1\n",
      "2          1\n",
      "Name: count, Length: 135, dtype: int64\n",
      "\n",
      "Frecuencias para Gender:\n",
      "Gender\n",
      "2    7277\n",
      "1    5536\n",
      "3    2180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Color1:\n",
      "Color1\n",
      "1    7427\n",
      "2    3750\n",
      "3     947\n",
      "5     884\n",
      "6     684\n",
      "7     667\n",
      "4     634\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Color2:\n",
      "Color2\n",
      "0    4471\n",
      "7    3438\n",
      "2    3313\n",
      "5    1128\n",
      "6    1063\n",
      "4     870\n",
      "3     710\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Color3:\n",
      "Color3\n",
      "0    10604\n",
      "7     3221\n",
      "5      417\n",
      "6      378\n",
      "4      198\n",
      "3      175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para MaturitySize:\n",
      "MaturitySize\n",
      "2    10305\n",
      "1     3395\n",
      "3     1260\n",
      "4       33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para FurLength:\n",
      "FurLength\n",
      "1    8808\n",
      "2    5361\n",
      "3     824\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Vaccinated:\n",
      "Vaccinated\n",
      "2    7227\n",
      "1    5898\n",
      "3    1868\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Dewormed:\n",
      "Dewormed\n",
      "1    8397\n",
      "2    4815\n",
      "3    1781\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Sterilized:\n",
      "Sterilized\n",
      "2    10077\n",
      "1     3101\n",
      "3     1815\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para Health:\n",
      "Health\n",
      "1    14478\n",
      "2      481\n",
      "3       34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para State:\n",
      "State\n",
      "41326    8714\n",
      "41401    3845\n",
      "41327     843\n",
      "41336     507\n",
      "41330     420\n",
      "41332     253\n",
      "41324     137\n",
      "41325     110\n",
      "41335      85\n",
      "41361      26\n",
      "41345      22\n",
      "41367      15\n",
      "41342      13\n",
      "41415       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias para AdoptionSpeed:\n",
      "AdoptionSpeed\n",
      "4    4197\n",
      "2    4037\n",
      "3    3259\n",
      "1    3090\n",
      "0     410\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4. \n",
    "# a. Estadísticas descriptivas (continuas) y tablas de frecuencias (categóricas)\n",
    "\n",
    "# Separar las columnas continuas y categóricas\n",
    "columnas_continuas = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "columnas_categoricas = train_data.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Estadísticas descriptivas para variables continuas\n",
    "descripcion_continuas = train_data[columnas_continuas].describe()\n",
    "\n",
    "# Frecuencias por categorías para variables categóricas\n",
    "frecuencias_categoricas = {}\n",
    "for columna in columnas_categoricas:\n",
    "    frecuencias_categoricas[columna] = train_data[columna].value_counts()\n",
    "\n",
    "# Imprimir las estadísticas descriptivas para variables continuas\n",
    "print(\"Estadísticas descriptivas para variables continuas:\")\n",
    "print(descripcion_continuas)\n",
    "print()\n",
    "\n",
    "# Imprimir las frecuencias por categorías para variables categóricas\n",
    "for columna, frecuencias in frecuencias_categoricas.items():\n",
    "    print(f\"Frecuencias para {columna}:\")\n",
    "    print(frecuencias)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# b. Divido el dataset para poder trabajar con la librería profiling\n",
    "vbles_continuas = train_data.select_dtypes(include=['float64', 'int64'])\n",
    "vbles_categoricas = train_data.select_dtypes(include=['category']) \n",
    "\n",
    "# Armo sub-dataset de vbles categóricas para analizar\n",
    "vble_target = vbles_categoricas.filter(['AdoptionSpeed'], axis=1)\n",
    "vbles_cat_gral = vbles_categoricas.filter(['Type', 'State'], axis=1)\n",
    "vbles_cat_salud = vbles_categoricas.filter(['Vaccinated', 'Health', 'Sterilized', 'Dewormed' ], axis=1)\n",
    "vbles_cat_fisicas1 = vbles_categoricas.filter(['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3'], axis=1)\n",
    "vbles_cat_fisicas2 = vbles_categoricas.filter(['Gender', 'MaturitySize', 'FurLength'], axis=1)\n",
    "\n",
    "\n",
    "#print(vbles_continuas)\n",
    "#print(vbles_cat_gral)\n",
    "#print(vbles_cat_salud)\n",
    "#print(vbles_cat_fisicas1)\n",
    "#print(vbles_cat_fisicas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 39/39 [00:04<00:00,  8.94it/s, Completed]                 \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 227.85it/s]\n",
      "Summarize dataset: 100%|██████████| 10/10 [00:00<00:00, 14.21it/s, Completed]                    \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 1110.78it/s]\n",
      "Summarize dataset: 100%|██████████| 11/11 [00:00<00:00, 42.47it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 875.64it/s]\n",
      "Summarize dataset: 100%|██████████| 13/13 [00:00<00:00, 35.53it/s, Completed]                 \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 417.14it/s]\n",
      "Summarize dataset: 100%|██████████| 14/14 [00:00<00:00, 30.18it/s, Completed]                \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 328.99it/s]\n",
      "Summarize dataset: 100%|██████████| 12/12 [00:00<00:00, 39.39it/s, Completed]                 \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 500.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. EDA\n",
    "\n",
    "directorio_actual = os.getcwd()\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "EDA_cont = ProfileReport(vbles_continuas)\n",
    "EDA_cont.to_file(os.path.join(directorio_actual, \"EDA/EDA_continuas.html\"))\n",
    "\n",
    "EDA_target = ProfileReport(vble_target)\n",
    "EDA_target.to_file(os.path.join(directorio_actual, \"EDA/EDA_target.html\"))\n",
    "\n",
    "EDA_cat_gral = ProfileReport(vbles_cat_gral)\n",
    "EDA_cat_gral.to_file(os.path.join(directorio_actual, \"EDA/EDA_cat_gral.html\"))\n",
    "\n",
    "EDA_cat_salud = ProfileReport(vbles_cat_salud)\n",
    "EDA_cat_salud.to_file(os.path.join(directorio_actual, \"EDA/EDA_cat_salud.html\"))\n",
    "\n",
    "EDA_cat_fisicas1 = ProfileReport(vbles_cat_fisicas1)\n",
    "EDA_cat_fisicas1.to_file(os.path.join(directorio_actual, \"EDA/EDA_cat_fisicas1.html\"))\n",
    "\n",
    "EDA_cat_fisicas2 = ProfileReport(vbles_cat_fisicas2)\n",
    "EDA_cat_fisicas2.to_file(os.path.join(directorio_actual, \"EDA/EDA_cat_fisicas2.html\"))\n",
    "\n",
    "#del EDA_cont\n",
    "#del EDA_cat_gral\n",
    "#del EDA_cat_salud \n",
    "#del EDA_cat_fisicas1\n",
    "#del EDA_cat_fisicas2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio de los datos\n",
    "\n",
    "#### Análisis univariado\n",
    "\n",
    "El dataset no presenta valores faltantes.\n",
    "En relación al valor “cero”, son valores posibles para las variables indicando la ausencia del atributo que se está midiendo.\n",
    "\n",
    "*Variables continuas*\n",
    "\n",
    "Edad\n",
    "\n",
    "Se presenta una amplia variabilidad en las edades registradas. El rango de edades va desde un mínimo de 0 meses hasta un máximo de 255 meses, lo que indica que se incluyen mascotas de todas las edades. \n",
    "La mediana de la edad es de 3 meses, lo que sugiere que la mitad de las mascotas en el conjunto de datos son menores de 3 meses, mientras que la otra mitad son mayores de 3 meses. \n",
    "El rango intercuartil (RIQ) de 10 meses indíca que el 50% intermedio de las edades se encuentra en un rango de 2 meses a 12 meses. La desviación estándar de 18.16 indica una dispersión significativa en las edades. \n",
    "Se presentan edades extremas en este dataset.\n",
    "\n",
    "Cantidad (número de perfiles de las mascotas) \n",
    "\n",
    "Se evidencia que la mayoría de los valores se concentran en torno a un número bajo, ya que tanto la mediana como los cuartiles (Q1 y Q3) tienen un valor de 1. Además, el rango intercuartil (RIQ) es igual a 0, lo que indica que el 50% intermedio de los datos está en el mismo valor (1).\n",
    "Sin embargo, la variable muestra tambien una amplia dispersión en los datos. Esto sugiere que, aunque la mayoría de los perfiles de mascotas tienen una cantidad baja, existen algunos valores atípicos o extremos que contribuyen a esta dispersión. El coeficiente de variación (CV) es menor que 1, lo que indica una variabilidad relativamente baja en relación con la media.\n",
    "\n",
    "Tarifa de adopción\n",
    "\n",
    "Es evidente que una gran proporción de las adopciones se ofrecen de forma gratuita, ya que el valor mínimo, los percentiles 5, 25, 50 y 75, todos tienen un valor de 0. Esto indica que muchas mascotas se ofrecen sin costo alguno para los adoptantes.\n",
    "Sin embargo, también se observa una amplia variación en los datos, ya que el rango es de 3000, lo que significa que la tarifa máxima de adopción es 3000 veces mayor que la tarifa mínima. Esto se refleja en la alta desviación estándar y el coeficiente de variación (CV) mayor a 1, lo que indica una dispersión significativa en los datos en relación con la media.\n",
    "Por lo tanto, aunque la mayoría de las adopciones son gratuitas, existen casos excepcionales donde se cobra una tarifa sustancial por la adopción.\n",
    "\n",
    "Cantidad de videos\n",
    "\n",
    "La variable muestra que la gran mayoría de los perfiles de mascotas no incluyen videos, pero también señala una pequeña cantidad de casos excepcionales con un pequeño número de videos. La distribución de datos es altamente sesgada hacia la falta de videos.\n",
    "\n",
    "Cantidad de fotos\n",
    "\n",
    "La variable tiene un rango que va desde un mínimo de 0 (indicando que no hay fotos) hasta un máximo de 30 (indicando un valor extremo de fotos). Esto refleja la variedad en la cantidad de fotos que se incluyen en los perfiles de mascotas.\n",
    "Los percentiles y cuartiles muestran que la mayoría de los perfiles de mascotas tienen al menos algunas fotos, ya que el percentil 5, el primer cuartil (Q1) y la mediana son mayores que 0. El tercer cuartil (Q3) indica que el 75% de los perfiles tienen 5 fotos o menos, y el percentil 95 indica que la gran mayoría de los perfiles tienen 10 fotos o menos.\n",
    "La distribución de datos tiende a concentrarse en valores bajos, pero permite un número variable de fotos en algunos perfiles.\n",
    "\n",
    "*Variables categóricas*\n",
    "\n",
    "En líneas generales podemos decir que:\n",
    "\n",
    "El Train_data contiene un 54.2% de perros y un 45.8% de gatos. El mayor porcentaje de dichas mascotas corresponden a el estado de Selampor (58.1%) y Kualu Lumpur (25.6%).\n",
    "En relación a caracteristicas físicas, observamos que en relación a la raza principal predomina la \"raza mixta\" (perro) (39,5%) y \"Siberian Husky\" (perro) (24.2%)\". En menor medida, se encuentra la \"doméstica de pelo medio\" (gato) (8.4%). El resto de las razas tienen frecuencias menores al 2.5%.\n",
    "El color principal de relevancia de las mascotas es el negro (49.5%) y en segundo lugar marrón (25%). El resto de los colores tienen frecuencias menores al 6.5%.\n",
    "La mayoría de las mascotas son hembras (48.5%). El tamaño predominante es el mediano (68.7%) y la longitud del pelaje es sobresaliente para los pelo corto (58.7%).\n",
    "En cuestiones de salud, un 48,2% no poseen sus vacunas y un 39.3% si poseen. Del resto de las mascotas, este dato se desconoce. Así mismo, casi la totalidad de las mascotas (96.6%) son saludables. El 67.2% no ha sido castrada y el 56.2% está deparasitada.\n",
    "\n",
    "Velocidad de adopción\n",
    "\n",
    "Algunas mascotas (2,7%) son adoptadas inmediatamente. Sin embargo, esto es raro (suerte).\n",
    "Muchas mascotas no son adoptadas en absoluto (28%) y un 26,9% en el primer mes que se encuentran en el listado.\n",
    "Las frecuencias en la rápidez de adopción no muestran diferencias significativas entre el resto de los períodos, con lo cuál sería necesario un análisis bivariado de la variable en cuestión para obtener otro tipo de conclusiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis Bivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Temp\\ipykernel_18680\\4182655612.py:18: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion() \n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado 'df' con las variables categóricas 'variable1' y 'variable2'\n",
    "\n",
    "# Crear el gráfico de barras bivariado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='Type', hue='AdoptionSpeed')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Gráfico de Barras Bivariado')\n",
    "plt.legend(title='AdoptionSpeed', loc='upper right')  # Agregar leyenda\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Primer Corrida\n",
    "\n",
    "Se generan los primeros modelos () sin agregado de informacion. Dividimos los datos en train y test que luego mantendremos durante todo el notebook. A estos conjuntos se agregara informacion con la intencion de mejorar la prediccion. Entonces, evaluaremos resultados en train, test y con modelos anteriores que tendran menos variables.\n",
    "\n",
    "Se compararan cuatros modelos:\n",
    "\n",
    "1. Ridge Classifier\n",
    "2. K Neighbors Classifier\n",
    "3. Extra Trees Classifier\n",
    "4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias necearias para esta etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importo librerias\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#Librerias para graficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme() \n",
    "\n",
    "#import cv2 #Para cargar/mostrar/procesar imagenes\n",
    "import json\n",
    "import glob #Para listar los archivos en una carpeta\n",
    "\n",
    "# Librerias propias (contienen los modelos)\n",
    "import model_metadata\n",
    "import model_sentiment\n",
    "\n",
    "# Librerias necesarias para modelos de clasificacion\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_train(train_data, train_idx):\n",
    "    X = train_data.drop(\"AdoptionSpeed\", axis=1).iloc[train_idx]\n",
    "    y = train_data[\"AdoptionSpeed\"].iloc[train_idx]\n",
    "    return X, y\n",
    "\n",
    "def get_X_y_val(train_data, val_idx):\n",
    "    X = train_data.drop(\"AdoptionSpeed\", axis=1).iloc[val_idx]\n",
    "    y = train_data[\"AdoptionSpeed\"].iloc[val_idx]\n",
    "    return X, y\n",
    "\n",
    "#Variable global\n",
    "\n",
    "\n",
    "# Crear un diccionario para mantener los codificadores por columna\n",
    "CODIFICADORES = {}\n",
    "\n",
    "\n",
    "\n",
    "def get_data_prep(train_data):\n",
    "\n",
    "    #Borrado de columnas\n",
    "    data_prep = train_data.drop(\"Description\", axis=1)\n",
    "    #train_data = train_data.drop(\"Name\", axis=1)\n",
    "\n",
    "    #Encoder para variables discretas\n",
    "    columnas_encoder = ['Name', 'RescuerID']\n",
    "    for columna in columnas_encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        data_prep[columna] = encoder.fit_transform(data_prep[columna])\n",
    "        CODIFICADORES[columna] = encoder\n",
    "\n",
    "    return data_prep\n",
    "\n",
    "def evaluate_model(y_true, y_pred, set_name, model_name):\n",
    "    rta = {}\n",
    "\n",
    "    rta['set_name'] = set_name\n",
    "    rta['model_name'] = model_name\n",
    "    rta['accuracy_average_weighted'] = accuracy_score(y_true, y_pred)\n",
    "    rta['precision_average_weighted'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    rta['recall_average_weighted'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    rta['f1_average_weighted'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    rta['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    rta['precision'] = precision_score(y_true, y_pred, average=None)\n",
    "    rta['recall'] = recall_score(y_true, y_pred, average=None)\n",
    "    rta['f1'] = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    return rta\n",
    "\n",
    "def get_feature_importances(data, modelos):\n",
    "    '''en desarrollo'''\n",
    "    #RidgeClassifier\n",
    "    rta=[]\n",
    "    for modelo in modelos:\n",
    "        if type(modelo).__name__ == 'RidgeClassifier':\n",
    "            feature_importances = modelo.coef_[0]\n",
    "        elif type(modelo).__name__ == 'RandomForestClassifier':\n",
    "            feature_importances = modelo.feature_importances_\n",
    "        elif type(modelo).__name__ == 'ExtraTreesClassifier':\n",
    "            feature_importances = modelo.feature_importances_\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        rta_model = []\n",
    "        for feature, importance in zip(data.columns, feature_importances):\n",
    "            rta_model.append((feature, importance))\n",
    "\n",
    "        rta.append(sorted(rta_model, key=lambda x: abs(x[1]), reverse=True))\n",
    "\n",
    "    return rta\n",
    "\n",
    "#Esta funcion importa los archivos json a una lista de objetos. Para luego generar las variables.\n",
    "def get_object_model(model, listFileFullPath):\n",
    "    '''\n",
    "        model = clase del modelo que se quiere cargar (objeto)\n",
    "        listFullPath = ruta completa de los archivos a cargar (List[string])\n",
    "    '''\n",
    "\n",
    "    listObject = []\n",
    "    for file in listFileFullPath:\n",
    "        \n",
    "        file_json = None\n",
    "        objectModel = None\n",
    "        \n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as archivo:  # Especifica la codificación utf-8 o la que corresponda\n",
    "               file_json = json.load(archivo)\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error de decodificación en el archivo '{file}': {e}\")\n",
    "            continue  # Continúa con el siguiente archivo en caso de error\n",
    "        \n",
    "        \n",
    "        fileName = file.split('/')[-1]\n",
    "        file_json['fileName'] = fileName\n",
    "        file_json['PetID'] = fileName.split('.')[0].split('-')[0]\n",
    "        objectModel = model.Model(**file_json)\n",
    "        listObject.append(objectModel)\n",
    "\n",
    "    return listObject \n",
    "\n",
    "def get_fit_transform(X_train, y_train, X_val, y_val, modelos):\n",
    "    resultados = []\n",
    "    for modelo in modelos:\n",
    "    \n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_train_pred = modelo.predict(X_train)\n",
    "        y_val_pred = modelo.predict(X_val)\n",
    "        #rta = evaluate_model(y_train, y_train_pred, \"Training\", type(modelo).__name__)\n",
    "        #rta.append(get_feature_importances(modelo))\n",
    "        resultados.append(evaluate_model(y_train, y_train_pred, \"Training\", type(modelo).__name__))\n",
    "        resultados.append(evaluate_model(y_val, y_val_pred, \"Validation\", type(modelo).__name__))\n",
    "\n",
    "    return resultados\n",
    "HIPER = []\n",
    "def get_fit_transform_CV(X_train, y_train, X_val, y_val, modelos, params_grids):\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for modelo,param_grid  in zip(modelos, params_grids):\n",
    "        print(type(modelo).__name__)\n",
    "        grid = GridSearchCV(estimator = modelo, param_grid = param_grid,\n",
    "                            cv = 5, n_jobs = -1, verbose = 0)\n",
    "        grid.fit(X_train, y_train)\n",
    "        HIPER.append((grid.best_estimator_, type(modelo).__name__))\n",
    "        y_train_pred = grid.best_estimator_.predict(X_train)\n",
    "        y_val_pred = grid.best_estimator_.predict(X_val)\n",
    "        resultados.append(evaluate_model(y_train, y_train_pred, \"Training\", type(modelo).__name__))\n",
    "        resultados.append(evaluate_model(y_val, y_val_pred, \"Validation\", type(modelo).__name__))\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division Train y Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 11994\n",
      "Val: 2999\n"
     ]
    }
   ],
   "source": [
    "#Lectura Dataset inicial \n",
    "TRAIN_DATA = pd.read_csv('../data/train/train.csv', index_col='PetID') \n",
    "# Divide tus datos en conjuntos de entrenamiento y validación. Mantenemos siempre los mismos indices\n",
    "train_idx, val_idx = train_test_split(range(len(TRAIN_DATA)), test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train_idx)}\")\n",
    "print(f\"Val: {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera corrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11994, 21)\n",
      "Val: (11994,)\n",
      "Train: (2999, 21)\n",
      "Val: (2999,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inicializa los modelos\n",
    "ridge_classifier = RidgeClassifier()\n",
    "kneighbors_classifier = KNeighborsClassifier()\n",
    "extra_trees_classifier = ExtraTreesClassifier()\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "#Modelos a evaluar\n",
    "MODELOS = [ridge_classifier, kneighbors_classifier, extra_trees_classifier, random_forest_classifier]\n",
    "#Resultados de las distintas iteraciones que se vayan realizando\n",
    "RESULTADOS = []\n",
    "PARAMS = []\n",
    "FEATURE_IMPORTANCES = []\n",
    "\n",
    "#Primera iteracion con los datos como vienen.\n",
    "data = get_data_prep(TRAIN_DATA)\n",
    "X_train, y_train = get_X_y_train(data, train_idx)\n",
    "X_val, y_val = get_X_y_val(data, val_idx)\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val: {y_train.shape}\")\n",
    "print(f\"Train: {X_val.shape}\")\n",
    "print(f\"Val: {y_val.shape}\")\n",
    "\n",
    "RESULTADOS.append(get_fit_transform(X_train, y_train, X_val, y_val, MODELOS))\n",
    "FEATURE_IMPORTANCES.append(get_feature_importances(data, MODELOS))\n",
    "PARAMS.append(PARAMS.append([modelo.get_params() for modelo in MODELOS]))\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizacion de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_GRID = [\n",
    "{\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "    #'normalize': [True, False]\n",
    "},\n",
    "{\n",
    "    'leaf_size': [20, 25, 30, 35, 40],\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'distance': ['uniform', 'distance'],\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "},\n",
    "{\n",
    "    'n_estimators': [25, 50, 80, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "},\n",
    "{\n",
    "    'n_estimators': [25, 50, 80, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Elemir Celis Mendoza\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "RESULTADOS.append(get_fit_transform_CV(X_train, y_train, X_val, y_val, MODELOS, PARAM_GRID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Buscar el modelo optimo\n",
    "\n",
    "Se realizara un proceso evolutivo, donde iremos agregando variables y re-evaluando los modelos. Con la intencion de verificar si existe mejora o no con el agregar de las variables. Para esto se evaluaran las mismas metricas vistas anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Sentimientos de las descripciones\n",
    "\n",
    "Informacion disponible de los comentarios:\n",
    "\n",
    "1. magnitude.\n",
    "2. score.\n",
    "3. Cantidad de sentencias.\n",
    "4. EntidadCantidad.\n",
    "5. Entidad por tipo (son varias columnas).\n",
    "6. Idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion de funciones para obtener las nuevas variables\n",
    "\n",
    "getPetID = lambda x: x.PetID\n",
    "getPetID_vec = np.vectorize(getPetID)\n",
    "\n",
    "#Solo para la modelo model_sentiment\n",
    "#1. magnitude\n",
    "getMagnitude = lambda x: x.documentSentiment.magnitude\n",
    "getMagnitude_vec = np.vectorize(getMagnitude)\n",
    "\n",
    "#2. score\n",
    "getScore = lambda x: x.documentSentiment.score\n",
    "getScore_vec = np.vectorize(getScore)\n",
    "\n",
    "#3. Cantidad de sentencias\n",
    "getLenEntity = lambda x: len(x.entities)\n",
    "getLenEntity_vec = np.vectorize(getLenEntity)\n",
    "\n",
    "#4. EntidadCantidad\n",
    "getLenSentences = lambda x: len(x.sentences)\n",
    "getLenSentences_vec = np.vectorize(getLenSentences)\n",
    "\n",
    "# 5. Entidad por tipo (son varias columnas)\n",
    "getEntitiesCount = lambda x: x.get_entity_count()\n",
    "getEntitiesCount_vec = np.vectorize(getEntitiesCount)\n",
    "\n",
    "# 6. Idioma (despues hay que hacer un encoder)\n",
    "# Es necesario hacerle un encoder a esta variable\n",
    "getLenguage = lambda x: x.language\n",
    "getLenguage_vec = np.vectorize(getLenguage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los archivos sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de archivos sentiments\n",
    "f_train_sentiments = glob.glob('../data/train_sentiment/*.json')\n",
    "f_train_sentiments= [ruta.replace('\\\\', '/') for ruta in f_train_sentiments]\n",
    "LIST_SENTIMENTS = get_object_model(model_sentiment, f_train_sentiments)\n",
    "del f_train_sentiments\n",
    "\n",
    "#Se agrega informacion de los archivo sentiment\n",
    "#Si tiene o no archivo sentiment\n",
    "data = get_data_prep(TRAIN_DATA)\n",
    "data['sentiment?'] = data.index.isin(getPetID_vec(LIST_SENTIMENTS))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "        data = {'Score' : getScore_vec(LIST_SENTIMENTS).tolist()\n",
    "                ,'Magnitude' : getMagnitude_vec(LIST_SENTIMENTS).tolist()\n",
    "                ,'CountEntity' : getLenEntity_vec(LIST_SENTIMENTS).tolist()\n",
    "                ,'CountSentences' : getLenSentences_vec(LIST_SENTIMENTS).tolist()\n",
    "                ,'EntitiesCount' : getEntitiesCount_vec(LIST_SENTIMENTS).tolist()\n",
    "                ,'Lenguage': getLenguage_vec(LIST_SENTIMENTS).tolist()\n",
    "                }\n",
    "        , index=getPetID_vec(LIST_SENTIMENTS))\n",
    "\n",
    "df_EntitiesCount = (df['EntitiesCount'].apply(lambda x: pd.Series(x, dtype=float))).fillna(0).astype(int)\n",
    "df_EntitiesCount.columns = ['EntitiesCount_' + str(col) for col in df_EntitiesCount.columns]\n",
    "\n",
    "df.drop('EntitiesCount', axis=1, inplace=True)\n",
    "df.index.name = 'PetID'\n",
    "#agrego las columnas de EntitiesCount\n",
    "df = df.join(df_EntitiesCount, on='PetID', how='left', lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "\n",
    "\n",
    "df = data.join(df, on='PetID', how='left', lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "del df_EntitiesCount\n",
    "del df\n",
    "del LIST_SENTIMENTS\n",
    "\n",
    "\n",
    "#Segunda iteracion agregando las variables de sentiment\n",
    "X_train, y_train = get_X_y_train(data, train_idx)\n",
    "X_val, y_val = get_X_y_val(data, val_idx)\n",
    "\n",
    "RESULTADOS.append(get_fit_transform(X_train, y_train, X_val, y_val, MODELOS))\n",
    "\n",
    "del data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Labo_II",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
